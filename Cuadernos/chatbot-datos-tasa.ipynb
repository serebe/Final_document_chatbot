{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descarga de librerias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T19:02:38.118923Z",
     "iopub.status.busy": "2025-07-13T19:02:38.118319Z",
     "iopub.status.idle": "2025-07-13T19:02:38.122161Z",
     "shell.execute_reply": "2025-07-13T19:02:38.121345Z",
     "shell.execute_reply.started": "2025-07-13T19:02:38.118897Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# pip install pandas transformers langchain langchain-community torch faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T19:02:55.731069Z",
     "iopub.status.busy": "2025-07-13T19:02:55.730388Z",
     "iopub.status.idle": "2025-07-13T19:03:31.316656Z",
     "shell.execute_reply": "2025-07-13T19:03:31.315892Z",
     "shell.execute_reply.started": "2025-07-13T19:02:55.731042Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/scuartasr/Documents/MaestriÌa/pdd/Final_document_chatbot/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import PyPDF2\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "# import pdfplumber\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lectura de archivos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€ CONFIGURACIÃ“N GENERAL â”€â”€â”€â”€â”€â”€â”€\n",
    "PDF_PATH = Path(r\"C:\\Users\\user\\Documents\\chatbot\\riesgo-credito-2.pdf\")\n",
    "EMBEDDING_MODEL = \"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\"\n",
    "LLM_MODEL = \"google/flan-t5-large\"\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€ CHISTES FINANCIEROS (opcional) â”€â”€â”€â”€â”€â”€â”€\n",
    "financial_jokes = [\n",
    "    \"Â¿Por quÃ© el banco no le prestÃ³ al fantasma? Â¡Porque no tenÃ­a historial crediticio!\",\n",
    "    \"Â¿QuÃ© le dijo el riesgo de crÃ©dito al cliente? Â¡No te preocupes, solo estoy evaluando tu *score*!\",\n",
    "    \"Â¿Por quÃ© el analista de crÃ©dito estÃ¡ soltero? Porque siempre ve demasiado riesgo en las relaciones.\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definicion funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def extract_text_with_pypdf2(path: str) -> str:\n",
    "    text = \"\"\n",
    "    with open(path, \"rb\") as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        for page in reader.pages:\n",
    "            page_text = page.extract_text()\n",
    "            page_text=page_text.lower()\n",
    "            if page_text:\n",
    "                text += page_text + \"\\n\"\n",
    "    return text.strip()\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€ GUARDADO DE CONVERSACIÃ“N â”€â”€â”€â”€â”€â”€â”€\n",
    "def save_conversation(user_input: str, response: str, log_path: Path = Path(\"chat_history.txt\")):\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    with open(log_path, \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(f\"[{timestamp}] Usuario: {user_input}\\n\")\n",
    "        f.write(f\"[{timestamp}] Chatbot: {response}\\n\\n\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€ CONSTRUCCIÃ“N DE VECTORSTORE â”€â”€â”€â”€â”€â”€â”€\n",
    "def build_vectorstore(text: str):\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1500,\n",
    "        chunk_overlap=200,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \".\",\"-\",\":\"]\n",
    "    )\n",
    "    chunks = splitter.split_text(text)\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL)\n",
    "    return FAISS.from_texts(chunks, embeddings)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€ CARGA DEL MODELO LLM â”€â”€â”€â”€â”€â”€â”€\n",
    "def build_llm_pipeline():\n",
    "    tokenizer = AutoTokenizer.from_pretrained(LLM_MODEL)\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(LLM_MODEL)\n",
    "    pipe = pipeline(\n",
    "        \"text2text-generation\",\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        max_new_tokens=150\n",
    "    )\n",
    "    return HuggingFacePipeline(pipeline=pipe)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€ CREACIÃ“N DE QA CHAIN â”€â”€â”€â”€â”€â”€â”€\n",
    "def build_qa_chain(vector_store, llm):\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"context\", \"question\"],\n",
    "        template=\"\"\"\n",
    "Responde como experto colombiano en analisis financiero. \n",
    "da respuestas cortas y concretas,se amistoso, y ten capacidad para conectar con los demas,\n",
    "Usa Ãºnicamente la informaciÃ³n del contexto.\n",
    "\n",
    "Contexto:\n",
    "{context}\n",
    "\n",
    "Pregunta:\n",
    "{question}\n",
    "\n",
    "Respuesta:\n",
    "\"\"\"\n",
    "    )\n",
    "    return RetrievalQA.from_chain_type(\n",
    "        llm=llm,\n",
    "        chain_type=\"stuff\",\n",
    "        retriever=vector_store.as_retriever(search_kwargs={\"k\": 3}),\n",
    "        return_source_documents=True,\n",
    "        chain_type_kwargs={\"prompt\": prompt, \"document_variable_name\": \"context\"}\n",
    "    )\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€ RESPUESTA DEL CHATBOT â”€â”€â”€â”€â”€â”€â”€\n",
    "def chatbot_response(user_input: str, qa_chain) -> str:\n",
    "    input_lc = user_input.lower()\n",
    "    if input_lc.startswith((\"hola\", \"buenas\", \"quÃ© tal\", \"cÃ³mo estÃ¡s\", \"como estas\")):\n",
    "        response = \"Â¡Hola! Estoy aquÃ­ para ayudarte con lo que necesites sobre riesgo de crÃ©dito en Colombia. Â¿QuÃ© deseas saber?\"\n",
    "    elif \"chiste\" in input_lc:\n",
    "        response = random.choice(financial_jokes)\n",
    "    else:\n",
    "        try:\n",
    "            result = qa_chain({\"query\": user_input})\n",
    "            response = result.get(\"result\", \"\").strip()\n",
    "            if not response:\n",
    "                response = \"No encontrÃ© informaciÃ³n suficiente en el documento. Â¿PodrÃ­as reformular tu pregunta?\"\n",
    "        except Exception as e:\n",
    "            response = f\"ğŸ’¥ Hubo un error procesando tu pregunta: {str(e)}\"\n",
    "    save_conversation(user_input, response)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T18:01:31.445208Z",
     "iopub.status.busy": "2025-07-13T18:01:31.444575Z",
     "iopub.status.idle": "2025-07-13T18:04:50.025146Z",
     "shell.execute_reply": "2025-07-13T18:04:50.024256Z",
     "shell.execute_reply.started": "2025-07-13T18:01:31.445182Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“„ Extrayendo contenido del PDF...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\user\\\\Documents\\\\chatbot\\\\riesgo-credito-2.pdf'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 27\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatbot:\u001b[39m\u001b[38;5;124m\"\u001b[39m, chatbot_response(user_input, qa_chain))\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 27\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 4\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmain\u001b[39m():\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mğŸ“„ Extrayendo contenido del PDF...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m     context \u001b[38;5;241m=\u001b[39m \u001b[43mextract_text_with_pypdf2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPDF_PATH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m context:\n\u001b[1;32m      6\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mâš ï¸ No se pudo procesar el PDF.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m, in \u001b[0;36mextract_text_with_pypdf2\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mextract_text_with_pypdf2\u001b[39m(path: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m      2\u001b[0m     text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m      4\u001b[0m         reader \u001b[38;5;241m=\u001b[39m PyPDF2\u001b[38;5;241m.\u001b[39mPdfReader(file)\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m page \u001b[38;5;129;01min\u001b[39;00m reader\u001b[38;5;241m.\u001b[39mpages:\n",
      "File \u001b[0;32m~/Documents/MaestriÌa/pdd/Final_document_chatbot/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\user\\\\Documents\\\\chatbot\\\\riesgo-credito-2.pdf'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€ EJECUCIÃ“N PRINCIPAL â”€â”€â”€â”€â”€â”€â”€\n",
    "def main():\n",
    "    print(\"ğŸ“„ Extrayendo contenido del PDF...\")\n",
    "    context = extract_text_with_pypdf2(PDF_PATH)\n",
    "    if not context:\n",
    "        print(\"âš ï¸ No se pudo procesar el PDF.\")\n",
    "        return\n",
    "\n",
    "    print(\"ğŸ” Construyendo base de conocimiento vectorial...\")\n",
    "    vector_store = build_vectorstore(context)\n",
    "\n",
    "    print(\"ğŸ§  Cargando modelo de lenguaje...\")\n",
    "    llm = build_llm_pipeline()\n",
    "\n",
    "    print(\"ğŸ”— Preparando sistema de preguntas y respuestas...\")\n",
    "    qa_chain = build_qa_chain(vector_store, llm)\n",
    "\n",
    "    print(\"ğŸ¤– Asistente listo. Escribe 'salir' para terminar.\")\n",
    "    while True:\n",
    "        user_input = input(\"TÃº: \").strip()\n",
    "        if user_input.lower() == \"salir\":\n",
    "            print(\"ğŸ‘‹ Â¡Hasta pronto!\")\n",
    "            break\n",
    "        print(\"Chatbot:\", chatbot_response(user_input, qa_chain))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7855877,
     "sourceId": 12453761,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7861020,
     "sourceId": 12461421,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7861822,
     "sourceId": 12462630,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
